'''
Runs the streamlit app
Call this file in the terminal via `streamlit run app.py`
'''
import streamlit as st

from streamlit_extras.colored_header import colored_header
from streamlit_option_menu import option_menu
from streamlit_extras.badges import badge
from streamlit_shap import st_shap
from streamlit_card import card

from utils import *

from prettytable import PrettyTable

import sqlite3
import os

import requests
from openai import OpenAI

import pandas as pd


# import os
# import streamlit as st
# from streamlit_option_menu import option_menu
# from streamlit_extras.colored_header import colored_header
# from prettytable import PrettyTable




#         page_title="MLMD",
#         page_icon="ğŸ",
#         layout="centered",
#         initial_sidebar_state="auto",
#         menu_items={
#         })

# sysmenu = '''
# <style>
# MainMenu {visibility:hidden;}
# footer {visibility:hidden;}
# '''

# # https://icons.bootcss.com/
# st.markdown(sysmenu,unsafe_allow_html=True)
DEFAULT_STORAGE_PATH = "data"


def HEA_PPID():
    with st.sidebar:
        select_option = option_menu("", ["Home Page", "Model Inference", "Chat with Model"],

                                    menu_icon="boxes", default_index=0)
        st.write('''
            **Contact**: 



    ''')
        # æ­¤å‡½æ•°ä¸ºå®šä¹‰ä¸»é¡µé¢çš„é€‰æ‹©æ¡†åç»­ä¸ºé€‰æ‹©æ¡†çš„å„ä¸ªå†…å®¹ã€‚

    if select_option == "Home Page":
        colored_header(label="Model Inference", description=" ", color_name="violet-90")

        # é¡¹ç›®ç®€ä»‹
        st.subheader("é¡¹ç›®ç®€ä»‹")
        st.write("""
        æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªé«˜ç†µåˆé‡‘ç½‘ç»œé¢„æµ‹å¹³å°ï¼Œæ—¨åœ¨ä¸ºæ— äººå·¥æ™ºèƒ½åŸºç¡€çš„ææ–™ç ”ç©¶è€…æä¾›ä¾¿æ·çš„å·¥å…·å’Œæ¨¡å‹ã€‚è¯¥å¹³å°åŸºäºæœ€æ–°çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œèƒ½å¤Ÿå‡†ç¡®é¢„æµ‹é«˜ç†µåˆé‡‘çš„æ€§èƒ½ï¼Œæ¨åŠ¨åˆé‡‘ææ–™çš„ç ”å‘å’Œåº”ç”¨ã€‚
        """)

        # ä½¿ç”¨çš„ç®—æ³•
        st.subheader("ä½¿ç”¨çš„ç®—æ³•")
        st.write("""
        - **æ”¯æŒå‘é‡æœº (SVM)**
        - **TabPFNå›å½’**
        - **XGBoost**
        """)

        # é¡¹ç›®æˆå‘˜
        st.subheader("é¡¹ç›®æˆå‘˜")
        st.write("""
        - **é¡¹ç›®ç»„é•¿ï¼š** å‘¨å¤©æ¯…
        - **ç»„å‘˜ï¼š** ï¼ˆå…·ä½“æˆå‘˜å¾…å®šï¼‰
        - **æŒ‡å¯¼è€å¸ˆï¼š** ç†Šæ°
        """)

        # è”ç³»æ–¹å¼
        st.subheader("è”ç³»æ–¹å¼")
        st.write("è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»é¡¹ç›®å›¢é˜Ÿï¼š")
        st.write("Email: example@example.com")

    elif select_option == "Model Inference":

        colored_header(label="Model Inference", description=" ", color_name="violet-90")

        model_source = st.selectbox('Select Function Block', [

            '[1] Use internal model (Here, select to call internal model)',

            '[2] Upload your own model (Please upload your model here)'

        ])

        if model_source == '[1] Use internal model (Here, select to call internal model)':

            # ======== å…ˆè‡ªåŠ¨æ£€ç´¢æ¨¡å‹ï¼Œå¹¶å§‹ç»ˆæ˜¾ç¤ºæ¨¡å‹é€‰æ‹©æ¡† ========
            model_dir = 'model_done'
            model_files = [f for f in os.listdir('model_done') if f.endswith(('.pkl', '.pickle'))]

            st.subheader("Select Internal Model")
            if model_files:
                model_selected = st.selectbox('Select internal model to use', model_files)
                model_path = os.path.join(model_dir, model_selected)

                try:
                    with open(model_path, 'rb') as f:
                        model = pickle.load(f)

                    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰ n_features_in_
                    if hasattr(model, 'n_features_in_'):
                        n_model_features = model.n_features_in_
                        st.info(f"â„¹ï¸ This model expects **{n_model_features} features** as input.")
                    else:
                        st.warning("âš ï¸ This model does not have `n_features_in_` attribute.")

                except Exception as e:
                    st.error(f"Error loading model: {e}")
                    model = None
                    n_model_features = None


            else:
                st.warning('No models found in model_done/ folder.')
                model_selected = None
                model_path = None

            st.markdown("### Manually Input Metals & Ratios")

            num_metals = st.number_input("Number of metals", min_value=1, max_value=20, value=3, step=1)

            metal_names = []
            metal_ratios = []

            st.markdown("### Enter Metal Names and Their Ratios")

            # åˆå§‹åŒ–
            num_metals = 10
            metal_names = []
            metal_ratios = []
            ratio_total = 0.0
            input_valid = True

            # å›ºå®šé‡‘å±å…ƒç´ 
            fixed_metals = ['Fe', 'Cu', 'Ni', 'Cr', 'Mn', 'Mo', 'Co', 'Zn']
            num_metals = len(fixed_metals)

            metal_ratios = []
            input_valid = True

            # è¡¨æ ¼è¾“å…¥ï¼Œæ¯åˆ—ä¸€ä¸ªé‡‘å± + 1åˆ—æ˜¾ç¤ºæ€»å’Œ
            cols = st.columns(num_metals + 1)

            # ç¬¬ä¸€è¡Œï¼šå±•ç¤ºé‡‘å±åç§°ï¼ˆä¸å¯ç¼–è¾‘ï¼‰
            for i in range(num_metals):
                with cols[i]:
                    st.markdown(f"**{fixed_metals[i]}**")

            # ç¬¬äºŒè¡Œï¼šè¾“å…¥æ¯”ä¾‹
            for i in range(num_metals):
                with cols[i]:
                    ratio = st.number_input(
                        "Ratio (%)", min_value=0.0, max_value=100.0, step=0.01, key=f"metal_ratio_{i}"
                    )
                    metal_ratios.append(ratio)

            # æœ€åä¸€åˆ—ï¼šæ˜¾ç¤ºæ€»æ¯”ä¾‹
            with cols[-1]:
                ratio_total = round(sum(metal_ratios), 2)
                st.markdown("**Total Ratio**")
                st.write(f"{ratio_total} %")

            # æ£€æŸ¥è¾“å…¥åˆæ³•æ€§
            if any(r < 0 or r > 100 for r in metal_ratios) or ratio_total != 100.0:
                input_valid = False
                st.error("Invalid input: All ratios must be between 0 and 100, and the total must equal 100.00%.")
            else:
                input_valid = True
                st.success("Valid input! Total ratio is 100.00%")

            # è¡¨å•ç”¨äºæ”¯æŒç¦ç”¨æŒ‰é’®
            with st.form(key="manual_input_form"):
                submit_button = st.form_submit_button(
                    label="Generate manual CSV and use for prediction",
                    disabled=not input_valid
                )

            if submit_button:
                df_manual = pd.DataFrame([metal_ratios], columns=fixed_metals)
                st.write("Generated Data:")
                st.write(df_manual)

                tmp_download_link = download_button(df_manual, "manual_input.csv", button_text="Download CSV")
                st.markdown(tmp_download_link, unsafe_allow_html=True)

                df_ready = df_manual
                st.success("Manual input ready to use!")

            # ======== åç»­æµç¨‹ï¼ˆç»Ÿä¸€ç”¨ df_readyï¼Œä¸ç®¡æ˜¯ä¸Šä¼  or æ‰‹åŠ¨å¡«å†™ï¼‰ ========
            if 'df_ready' in locals():
                df = df_ready
                check_string_NaN(df)

                colored_header(label="Data information", description=" ", color_name="violet-70")
                nrow = st.slider("rows", 1, len(df), 5)
                st.write(df.head(nrow))

                colored_header(label="Feature and target", description=" ", color_name="violet-70")

                target_num = st.number_input('target number', min_value=1, max_value=10, value=1)

                col_feature, col_target = st.columns(2)

                features = df.iloc[:, :-target_num]
                targets = df.iloc[:, -target_num:]

                with col_feature:
                    st.write(features.head())

                with col_target:
                    st.write(targets.head())

                colored_header(label="target", description=" ", color_name="violet-70")

                target_selected_option = st.selectbox('target', list(targets)[::-1])
                targets = targets[target_selected_option]

                preprocess = st.selectbox('data preprocess', [None, 'StandardScaler', 'MinMaxScaler'])

                if preprocess == 'StandardScaler':
                    features = StandardScaler().fit_transform(features)
                elif preprocess == 'MinMaxScaler':
                    features = MinMaxScaler().fit_transform(features)

                # ======== é¢„æµ‹éƒ¨åˆ†ï¼Œç‚¹å‡»æŒ‰é’®è§¦å‘ ========
                st.subheader("Run Prediction")

                if model_selected and st.button("Run Prediction"):
                    try:
                        with open(model_path, 'rb') as f:
                            model = pickle.load(f)

                        prediction = model.predict(features)

                        plot = customPlot()
                        plot.pred_vs_actual(targets, prediction)

                        r2 = r2_score(targets, prediction)
                        st.write('R2: {}'.format(r2))

                        result_data = pd.concat([targets, pd.DataFrame(prediction)], axis=1)
                        result_data.columns = ['actual', 'prediction']

                        with st.expander('prediction'):
                            st.write(result_data)

                            tmp_download_link = download_button(result_data, f'prediction.csv', button_text='download')
                            st.markdown(tmp_download_link, unsafe_allow_html=True)

                        st.write('---')

                    except FileNotFoundError:
                        st.error(f'Model file not found: {model_path}')




        elif model_source == '[2] Upload your own model (Please upload your model here)':

            file = st.file_uploader("Upload `.csv`file", label_visibility="collapsed", accept_multiple_files=True)

            if len(file) < 2:
                table = PrettyTable(['file name', 'class', 'description'])
                table.add_row(['file_1', 'data set (+test data)', 'data file'])
                table.add_row(['file_2', 'model', 'model'])
                st.write(table)
            elif len(file) == 2:
                df = pd.read_csv(file[0])
                model_file = file[1]

                try:
                    model = pickle.load(model_file)

                    if hasattr(model, 'n_features_in_'):
                        n_model_features = model.n_features_in_
                        st.info(f"â„¹ï¸ This model expects **{n_model_features} features** as input.")
                    else:
                        st.warning("âš ï¸ This model does not have `n_features_in_` attribute.")
                except Exception as e:
                    st.error(f"Error loading model: {e}")
                    model = None
                    n_model_features = None

                check_string_NaN(df)

                colored_header(label="Data information", description=" ", color_name="violet-70")
                nrow = st.slider("rows", 1, len(df), 5)
                df_nrow = df.head(nrow)
                st.write(df_nrow)

                colored_header(label="Feature and target", description=" ", color_name="violet-70")

                target_num = st.number_input('target number', min_value=1, max_value=10, value=1)

                col_feature, col_target = st.columns(2)
                # features
                features = df.iloc[:, :-target_num]
                # targets
                targets = df.iloc[:, -target_num:]
                with col_feature:
                    st.write(features.head())
                with col_target:
                    st.write(targets.head())
                colored_header(label="target", description=" ", color_name="violet-70")

                target_selected_option = st.selectbox('target', list(targets)[::-1])

                targets = targets[target_selected_option]
                preprocess = st.selectbox('data preprocess', [None, 'StandardScaler', 'MinMaxScaler'])
                if preprocess == 'StandardScaler':
                    features = StandardScaler().fit_transform(features)
                elif preprocess == 'MinMaxScaler':
                    features = MinMaxScaler().fit_transform(features)

                model = pickle.load(model_file)
                prediction = model.predict(features)
                # st.write(std)
                plot = customPlot()
                plot.pred_vs_actual(targets, prediction)
                r2 = r2_score(targets, prediction)
                st.write('R2: {}'.format(r2))
                result_data = pd.concat([targets, pd.DataFrame(prediction)], axis=1)
                result_data.columns = ['actual', 'prediction']
                with st.expander('prediction'):
                    st.write(result_data)
                    tmp_download_link = download_button(result_data, f'prediction.csv', button_text='download')
                    st.markdown(tmp_download_link, unsafe_allow_html=True)
                st.write('---')

    elif select_option == "Chat with Model":
        client = OpenAI(

            api_key="sk-214f8e7ee2e943e2a220cd0fd40058d3",  # âš ï¸å»ºè®®ç”¨ st.secrets æˆ–ç¯å¢ƒå˜é‡ä»£æ›¿æ˜æ–‡å¯†é’¥

            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"

        )

        st.title("ğŸ’¬ Chat with ç™¾ç‚¼ Qwen æ¨¡å‹")

        # ä¼šè¯çŠ¶æ€ç”¨äºä¿å­˜å¯¹è¯å†å²

        if "conversation" not in st.session_state:
            st.session_state.conversation = []

        # æ˜¾ç¤ºå†å²å¯¹è¯

        for msg in st.session_state.conversation:
            st.write(f"**{msg['role']}**: {msg['text']}")

        user_input = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜:")

        if st.button("å‘é€"):

            if user_input:

                # æ·»åŠ ç”¨æˆ·é—®é¢˜åˆ°å¯¹è¯

                st.session_state.conversation.append({"role": "ç”¨æˆ·", "text": user_input})

                try:

                    completion = client.chat.completions.create(

                        model="qwen-plus",

                        messages=[

                            {"role": "system", "content": "You are a helpful assistant."},

                            *[

                                {"role": "user" if m["role"] == "ç”¨æˆ·" else "assistant", "content": m["text"]}

                                for m in st.session_state.conversation if m["role"] != "ç³»ç»Ÿ"

                            ],

                            {"role": "user", "content": user_input}

                        ]

                    )

                    reply = completion.choices[0].message.content

                except Exception as e:

                    reply = f"è¯·æ±‚å¤±è´¥: {e}"

                # æ·»åŠ æ¨¡å‹å›å¤

                st.session_state.conversation.append({"role": "æ¨¡å‹", "text": reply})

                # åˆ·æ–°æ˜¾ç¤ºå¯¹è¯

                for msg in st.session_state.conversation:
                    st.write(f"**{msg['role']}**: {msg['text']}")

            else:

                st.warning("è¯·è¾“å…¥é—®é¢˜åå†ç‚¹å‡»å‘é€ã€‚")


if __name__ == "__main__":
    HEA_PPID()